# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GRm2G7Is8d_Z-0BBR-7zg-2JWFFrRway
"""

!pip install tensorflow keras

#  ANN TRAIN

# 1. Upload & unzip dataset
from google.colab import files
import zipfile, os

uploaded = files.upload()  # ch·ªçn file .zip (vd: data_mono.zip)
zip_path = next(iter(uploaded.keys()))

extract_path = "/content/P_mono"
!rm -rf {extract_path}
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# 2. Duy·ªát d·ªØ li·ªáu ·∫£nh
import cv2
import numpy as np

x_data, y_data = [], []
 # Correctly list the class directories within the nested folder
class_base_path = os.path.join(extract_path, "P_mono")
class_names = sorted([name for name in os.listdir(class_base_path) if os.path.isdir(os.path.join(class_base_path, name))])

print("Classes:", class_names)

for label, class_name in enumerate(class_names):
    class_dir = os.path.join(class_base_path, class_name)
  # Recursively walk through subdirectories to find image files
    for root, dirs, files_in_dir in os.walk(class_dir):
        for fname in files_in_dir:
            fpath = os.path.join(root, fname)
            # Check if the file is an image (basic check based on extension)
            if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):
                img = cv2.imread(fpath, cv2.IMREAD_GRAYSCALE)
                if img is None:
                    print(f"Warning: Could not read image file: {fpath}")
                    continue
                img_resized = cv2.resize(img, (60, 60))
                x_data.append(img_resized)
                y_data.append(label)

x_data = np.array(x_data, dtype="float32") / 255.0
y_data = np.array(y_data, dtype="int")

print("Dataset shape:", x_data.shape, y_data.shape)

  # 3. Reshape & one-hot
if x_data.shape[0] > 0: # Only proceed if data is loaded
  x_data = x_data.reshape(x_data.shape[0], 60*60)  # flatten
  from keras.utils import to_categorical
  y_data = to_categorical(y_data, num_classes=len(class_names))

  # 4. Chia train/test
  from sklearn.model_selection import train_test_split
  x_train, x_test, y_train, y_test = train_test_split(
      x_data, y_data, test_size=0.2, random_state=42
  )

  print("Train:", x_train.shape, y_train.shape)
  print("Test:", x_test.shape, y_test.shape)

  # 5. X√¢y d·ª±ng ANN
  from keras.models import Sequential
  from keras.layers import Dense
  from keras.layers import Dropout # Import Dropout layer

  model = Sequential()
  model.add(Dense(512, activation='relu', input_shape=(60*60,))) # Changed input shape
  model.add(Dropout(0.3)) # Added Dropout layer
  model.add(Dense(256, activation='relu')) # Added Dense layer
  model.add(Dropout(0.3)) # Added Dropout layer
  model.add(Dense(len(class_names), activation='softmax')) # Output layer with correct number of classes

  model.compile(optimizer="rmsprop",
                loss="categorical_crossentropy",
                metrics=["accuracy"])

  model.summary()

  # 6. Hu·∫•n luy·ªán
  history = model.fit(x_train, y_train,
                      epochs=500,
                      batch_size=128,
                      validation_data=(x_test, y_test))

  # 7. L∆∞u model
  model.save("final_model.h5")
  print("Model saved!")

# UP ·∫¢NH ƒê·ªÇ TEST

from google.colab import files
uploaded = files.upload()
fname = next(iter(uploaded.keys()))

import cv2
import numpy as np
import matplotlib.pyplot as plt

IMG_SIZE = 60

# 1. ƒê·ªçc ·∫£nh m√†u g·ªëc
img_color = cv2.imread(fname, cv2.IMREAD_COLOR)
if img_color is None:
    raise ValueError("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh test!")

# 2. T·∫°o b·∫£n resize grayscale ƒë·ªÉ predict
img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)
img_resized = cv2.resize(img_gray, (IMG_SIZE, IMG_SIZE)) # Changed image size
img_norm = img_resized.astype("float32") / 255.0
img_ready = img_norm.reshape(1, IMG_SIZE*IMG_SIZE) # Changed image size

# 3. D·ª± ƒëo√°n
preds = model.predict(img_ready)
digit = class_names[np.argmax(preds)]
print("‚úÖ D·ª± ƒëo√°n:", digit)

# 4. Hi·ªÉn th·ªã ·∫£nh
plt.imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))
plt.axis("off")
plt.title(f"D·ª± ƒëo√°n: {digit}")
plt.show()

from google.colab import files, output
import cv2, numpy as np, base64
from IPython.display import display, HTML

# ===== B·∫£ng √Ω nghƒ©a ch·ªâ tay =====
palmistry_info = {
    "Ch·ªâ tay ch·ªØ M": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ch·ªØ M th∆∞·ªùng ƒë∆∞·ª£c cho l√† c√≥ t√†i nƒÉng ƒë·∫∑c bi·ªát, th√¥ng minh, v√† may m·∫Øn. H·ªç c√≥ kh·∫£ nƒÉng l√£nh ƒë·∫°o, tr·ª±c gi√°c t·ªët v√† th∆∞·ªùng ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng l·ªõn trong s·ª± nghi·ªáp v√† cu·ªôc s·ªëng.",
    "Ch·ªâ tay ch·ªØ nh·∫•t": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ch·ªØ Nh·∫•t th∆∞·ªùng c√≥ t√≠nh c√°ch m·∫°nh m·∫Ω v√† quy·∫øt ƒëo√°n. H·ªç c√≥ kh·∫£ nƒÉng t·∫≠p trung cao ƒë·ªô v√† th∆∞·ªùng ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng trong nh·ªØng lƒ©nh v·ª±c ƒë√≤i h·ªèi s·ª± ki√™n tr√¨ v√† quy·∫øt t√¢m. Tuy nhi√™n, h·ªç c≈©ng c√≥ th·ªÉ g·∫∑p kh√≥ khƒÉn trong vi·ªác c√¢n b·∫±ng gi·ªØa l√Ω tr√≠ v√† c·∫£m x√∫c.",
    "Ch·ªâ tay ch·ªØ X": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ch·ªØ X th∆∞·ªùng ƒë∆∞·ª£c coi l√† c√≥ s·ª©c m·∫°nh b·∫£o v·ªá ƒë·∫∑c bi·ªát v√† may m·∫Øn. H·ªç c√≥ kh·∫£ nƒÉng v∆∞·ª£t qua kh√≥ khƒÉn v√† th∆∞·ªùng ƒë∆∞·ª£c b·∫£o v·ªá kh·ªèi nh·ªØng r·ªßi ro l·ªõn.",
    "Ch·ªâ tay ƒëu√¥i c√°": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ƒëu√¥i c√° th∆∞·ªùng ƒë∆∞·ª£c coi l√† c√≥ may m·∫Øn ƒë·∫∑c bi·ªát v√† th∆∞·ªùng g·∫∑p ƒë∆∞·ª£c nhi·ªÅu c∆° h·ªôi t·ªët trong cu·ªôc s·ªëng. H·ªç c√≥ kh·∫£ nƒÉng v∆∞·ª£t qua kh√≥ khƒÉn v√† ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng l·ªõn.",
    "Ch·ªâ tay m·∫Øt ph∆∞·ª£ng": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay m·∫Øt ph∆∞·ª£ng th∆∞·ªùng c√≥ tr·ª±c gi√°c t·ªët, tr√≠ tu·ªá cao v√† kh·∫£ nƒÉng nh√¨n xa tr√¥ng r·ªông. H·ªç th∆∞·ªùng ƒë∆∞·ª£c qu√Ω nh√¢n ph√π tr·ª£ v√† c√≥ nhi·ªÅu c∆° h·ªôi th√†nh c√¥ng trong cu·ªôc s·ªëng.",
    "Ch·ªâ tay th·ªèi v√†ng": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay th·ªèi v√†ng th∆∞·ªùng ƒë∆∞·ª£c cho l√† c√≥ t√†i l·ªôc, th·ªãnh v∆∞·ª£ng v√† th√†nh c√¥ng trong s·ª± nghi·ªáp. H·ªç c√≥ kh·∫£ nƒÉng qu·∫£n l√Ω t√†i ch√≠nh t·ªët v√† th∆∞·ªùng g·∫∑p may m·∫Øn trong kinh doanh.",
}

IMG_SIZE = 28  # cho model

# ===== H√†m d·ª± ƒëo√°n =====
def run_prediction():
    uploaded = files.upload()
    fname = next(iter(uploaded.keys()))

    # ƒê·ªçc ·∫£nh m√†u g·ªëc
    img_color = cv2.imread(fname)
    img_color = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)

    # Chu·∫©n b·ªã grayscale cho model
    img_gray = cv2.cvtColor(img_color, cv2.COLOR_RGB2GRAY)
    img_resized = cv2.resize(img_gray, (IMG_SIZE, IMG_SIZE))
    img_norm = img_resized.astype("float32")/255.0
    img_ready = img_norm.reshape(1, IMG_SIZE*IMG_SIZE)

    # D·ª± ƒëo√°n
    preds = model.predict(img_ready)[0]
    top_index = preds.argmax()
    top_label = class_names[top_index]
    top_prob = preds[top_index]

    # M√¥ t·∫£
    description = palmistry_info.get(top_label, "Th√¥ng tin v·ªÅ ƒë∆∞·ªùng ch·ªâ tay n√†y ch∆∞a c√≥ trong c∆° s·ªü d·ªØ li·ªáu.")

    # Encode ·∫£nh g·ªëc (gi·ªØ nguy√™n m√†u)
    max_display_w = 400
    h, w = img_color.shape[:2]
    scale = min(max_display_w / w, 1.0)
    new_w, new_h = int(w*scale), int(h*scale)
    img_display = cv2.resize(img_color, (new_w, new_h))

    _, buffer = cv2.imencode('.png', cv2.cvtColor(img_display, cv2.COLOR_RGB2BGR))
    img_base64 = base64.b64encode(buffer).decode('utf-8')

    # HTML k·∫øt qu·∫£
    html_result = f"""
        <div>
            <img src="data:image/png;base64,{img_base64}"
                 style="max-width:400px; border-radius:15px; box-shadow:0 0 20px #ba68c8;">
            <div style="margin-top:10px; font-size:24px; font-weight:bold; color:#E1BEE7; text-shadow:0 0 10px #ab47bc;">
                üîÆ K·∫øt qu·∫£: {top_label} ({top_prob*100:.2f}%)
            </div>
            <p style='margin-top:12px; font-size:18px; color:#CE93D8; font-family:Raleway;'>{description}</p>
        </div>
    """

    display(HTML(f"""
        <script>
            document.getElementById('result').innerHTML = `{html_result}`;
            document.getElementById('resetBtn').style.display = 'inline-block';
        </script>
    """))

# ===== Callback =====
def predict_palm(): run_prediction()
def reset_and_predict(): run_prediction()

output.register_callback('predict_palm', predict_palm)
output.register_callback('reset_and_predict', reset_and_predict)

# ===== HTML giao di·ªán huy·ªÅn b√≠ =====
display(HTML("""
<!DOCTYPE html>
<html lang="vi">
<head>
<meta charset="UTF-8">
<title>üîÆ Xem ch·ªâ tay huy·ªÅn b√≠ üîÆ</title>
<link href="https://fonts.googleapis.com/css2?family=Cinzel+Decorative:wght@700&family=Raleway:wght@400;600&display=swap" rel="stylesheet">
<style>
    body {
        font-family: 'Raleway', sans-serif;
        background: radial-gradient(circle at top, #2e003e, #000000 80%);
        text-align: center;
        padding: 50px;
        color: #fff;
    }
    h1 {
        font-family: 'Cinzel Decorative', cursive;
        color: #E1BEE7;
        font-size: 50px;
        margin-bottom: 30px;
        text-shadow: 0 0 20px #ba68c8, 0 0 40px #7b1fa2;
    }
    .card {
        background: rgba(20, 0, 30, 0.85);
        padding: 35px;
        border-radius: 20px;
        box-shadow: 0px 0px 30px rgba(138,43,226,0.7);
        max-width: 700px;
        margin: auto;
        border: 2px solid #9c27b0;
    }
    button {
        margin-top: 25px;
        padding: 14px 35px;
        font-size: 20px;
        border: none;
        border-radius: 50px;
        cursor: pointer;
        font-weight: bold;
        transition: all 0.3s ease;
        color: #fff;
    }
    #predictBtn {
        background: linear-gradient(45deg, #7b1fa2, #ab47bc);
        box-shadow: 0px 0px 20px rgba(171,71,188,0.9);
    }
    #predictBtn:hover {
        transform: scale(1.05);
        box-shadow: 0px 0px 30px rgba(186,104,200,1);
    }
    #resetBtn {
        background: linear-gradient(45deg, #4527a0, #5e35b1);
        display: none;
    }
    #result {
        margin-top: 30px;
        font-size: 26px;
        font-weight: bold;
        color: #CE93D8;
        text-shadow: 0 0 10px #f3e5f5;
    }
</style>
</head>
<body>
    <h1>üîÆ Xem ch·ªâ tay ‚Äì Gi·∫£i m√£ v·∫≠n m·ªánh üîÆ</h1>
    <div class="card">
        <button id="predictBtn" onclick="google.colab.kernel.invokeFunction('predict_palm', [], {});">
            ‚úã T·∫£i ·∫£nh b√†n tay & Xem ch·ªâ tay
        </button>
        <button id="resetBtn" onclick="google.colab.kernel.invokeFunction('reset_and_predict', [], {});">
            üîÑ Xem b√†n tay kh√°c
        </button>
        <div id="result"></div>
    </div>
</body>
</html>
"""))